# Python scripts for disambiguating patent data

The following collection of scripts performs pre- and
post-processing on patent data as part of the patent
inventor disambiguation process.

Follow development, subscribe to
[RSS
feed](https://github.com/funginstitute/patentprocessor/commits/master.atom).


## Contributing to the Patent Processor Project

Pull requests are welcome. Here are a few pointers which will make everything easier:

* Small, tightly constrained commits.
* New files should be in their own commit, and committed before they are used in subsequent commits.
* Commits should tell a story in a logical sequence. It should be possible to understand the gist
  of the development just from reading the commits (hard, but worthwhile goal).
* The ideal commit:
    * Unit (or similar) test for a single functionality.
    * Implementation to pass the unit test.
    * Documentation (the "why") of the function/method in the appropriate location (platform dependent).
    * 0 or 1 use of the new functionality in production.
    * Further uses of functionality should go in future commits.
* Formatting updates, code cleanup and renaming should go into independent commits.
* Submit only code which is covered by *working* unit tests.
* Testing scripts, including unit tests, integration tests and functional tests go in the `test` directory.
* Code which does work goes in the lib directory.
* Code which provides a workflow (i.e., processing patents or building necessary
  infrastructure) goes in the top level directory. In the future, much of this code may
  be put into a `bin` directory.
* Test code should follow the pattern `test/test_libfile.py`. This pattern may change in
  the future, whence this documentation will change at that time.

**You must rebase before issuing a pull request: `git pull --rebase <upstream> master`**.

## Configuring the Preprocessing Environment

In order to properly configure the preprocessing environment, the end user must
manually perform the following:

* Download the relevant XML files which need to be processed. These can be
  placed in any directory, but `parse.py` assumes the root directory `/`.

* Set the PATENTROOT environment variable (assuming a UNIX environment). This
  can be customized later using command line options, but for the purposes of
  running unit tests, it is necessary to actually export the environment
  variable, e.g.

  `export PATENTROOT = /path/to/xml/files`

* You *do not* need to have the `.sqlite3` files already in the project root 
  directory, as they will be automatically generated by `parse.py`.

## Processing patents

There are two ways to get started:

* `preprocess.sh` to get started. This will run the preprocessor on any files
  contained in the PATENTROOT directory (defaults to the root directory)

* run `parse.py` directly to customize which directories are processed and
  which regex is used to process the files. Run `parse.py -h` to see the
  relevant command-line options.


## Disambiguating

## Postprocessing

After disambiguating, the resulting unique inventors are listed by number in an output file
(e.g., `final.txt`). This output file then processed to tie the inventor number to the
inventor name in the input database. The program which performs this linking is in the
`c++` disambiguation code. After the linking is done, verification proceeds.

### Verification

Verifying the results of the disambiguation is performed using the `benchmark.py` script,
which compares the linked results database with a (specially formatted) CSV file containing
a list of inventor-patent instances which have been verified by direct communication with
each inventor.

----

[Contributors](https://github.com/doolin/patentprocessor/graphs/contributors)


